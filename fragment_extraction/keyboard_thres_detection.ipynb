{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import namedtuple\n",
    "from math import sqrt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "det_params_names = ['block_scale', 'sub_threshold', 'retr_type', 'retr_approx', 'min_poly']\n",
    "DetectorParams = namedtuple('DetectorParams', det_params_names)\n",
    "\n",
    "class ContoursDetector:\n",
    "    def __init__(self, det_params):\n",
    "        self.det_params = det_params        \n",
    "        \n",
    "    def create_threshold_image(self, image, reverse_color=False):   \n",
    "        if reverse_color:\n",
    "            image = cv2.bitwise_not(image)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        block_size = int(max(image.shape[0], image.shape[1]) / self.det_params.block_scale)\n",
    "        if block_size % 2 == 0:\n",
    "            block_size += 1\n",
    "        thresh_type = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "        sub_thres = self.det_params.sub_threshold\n",
    "        return cv2.adaptiveThreshold(gray_image, 255, thresh_type, cv2.THRESH_BINARY, block_size, sub_thres)       \n",
    "        \n",
    "    def is_contour_valid(self, contour):\n",
    "        poly_tolerance = 0.01 * cv2.arcLength(contour, True)\n",
    "        poly_approx = cv2.approxPolyDP(contour, poly_tolerance, True)\n",
    "        return (len(poly_approx) > self.det_params.min_poly)\n",
    "        \n",
    "    def get_white_contours(self, image, reverse_color=False):\n",
    "        threshold = self.create_threshold_image(image, reverse_color)\n",
    "        retr_type, retr_approx = self.det_params.retr_type, self.det_params.retr_approx        \n",
    "        _, contours, _ = cv2.findContours(threshold, retr_type, retr_approx)\n",
    "        return filter(self.is_contour_valid, contours)        \n",
    "        \n",
    "    def get_contours(self, image):\n",
    "        return self.get_white_contours(image, False) + self.get_white_contours(image, True)\n",
    "    \n",
    "    def create_contours_image(self, image, reverse_color=False):\n",
    "        contours_list = self.get_white_contours(image, reverse_color)\n",
    "        contours_image = image.copy()        \n",
    "        for cnt in contours_list:\n",
    "            contour_color = np.random.randint(255, size=3)\n",
    "            cv2.drawContours(contours_image, [cnt], 0, contour_color, -1)   \n",
    "        return contours_image\n",
    "    \n",
    "    def plot_internal_image(self, image, cmap=None):\n",
    "        plt.figure(figsize=(14, 9))        \n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.show()        \n",
    "    \n",
    "    def plot_contours_images(self, image):\n",
    "        self.plot_internal_image(image)\n",
    "        self.plot_internal_image(self.create_threshold_image(image, False), 'gray')\n",
    "        self.plot_internal_image(self.create_contours_image(image, False))        \n",
    "        self.plot_internal_image(self.create_threshold_image(image, True), 'gray')\n",
    "        self.plot_internal_image(self.create_contours_image(image, True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImageFragmentExtractor:\n",
    "    def __init__(self, image, fragment_scale):\n",
    "        self.image = image\n",
    "        self.fragment_scale = fragment_scale\n",
    "        \n",
    "    def get_scaled_size(self, start_point, end_point):\n",
    "        center_point = (start_point + end_point) / 2.0\n",
    "        start_scaled = center_point - self.fragment_scale * (center_point - start_point)\n",
    "        end_scaled = center_point + self.fragment_scale * (end_point - center_point)\n",
    "        return int(start_scaled), int(end_scaled)\n",
    "    \n",
    "    def extract_image_fragment(self, contour):\n",
    "        start_x, start_y, width, height = cv2.boundingRect(contour)\n",
    "        width, height = max(width, height), max(width, height)\n",
    "        start_x, end_x = self.get_scaled_size(start_x, start_x + width)\n",
    "        start_y, end_y = self.get_scaled_size(start_y, start_y + height)\n",
    "        return ((start_x, start_y), self.image[start_y:end_y, start_x:end_x, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImagePointFilter:\n",
    "    def __init__(self, filter_radius):\n",
    "        self.filter_radius = filter_radius\n",
    "        self.occupied_point_list = []\n",
    "        \n",
    "    def get_point_distance_square(self, point1, point2):\n",
    "        px, py = point1[0] - point2[0], point1[1] - point2[1]\n",
    "        return (px ** 2 + py ** 2)\n",
    "        \n",
    "    def validate_point(self, point):\n",
    "        for occupied_point in self.occupied_point_list:\n",
    "            dist = self.get_point_distance_square(point, occupied_point)\n",
    "            if dist <= self.filter_radius ** 2:\n",
    "                return False\n",
    "        self.occupied_point_list.append(point)\n",
    "        return True\n",
    "        \n",
    "    def filter_points(self, point_list):\n",
    "        return filter(self.validate_point, point_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageFragmentFilter:\n",
    "    def __init__(self, min_edge_size, max_edge_size, filter_radius=0):\n",
    "        self.min_edge_size = min_edge_size\n",
    "        self.max_edge_size = max_edge_size\n",
    "        self.filter_radius = filter_radius\n",
    "        self.image_point_filter = ImagePointFilter(filter_radius)\n",
    "        \n",
    "    def filter_fragments(self, fragment_list):\n",
    "        edge_size_func = (lambda x: min(x[1].shape[0], x[1].shape[1]))\n",
    "        fragment_list = filter(lambda x: edge_size_func(x) > self.min_edge_size, fragment_list)\n",
    "        fragment_list = filter(lambda x: edge_size_func(x) < self.max_edge_size, fragment_list)\n",
    "        if self.filter_radius == 0:\n",
    "            return fragment_list\n",
    "        point_list = map(lambda x: x[0], fragment_list)\n",
    "        point_set = set(self.image_point_filter.filter_points(point_list))\n",
    "        filtered_fragment_list = []\n",
    "        for point, image in fragment_list:  \n",
    "            if point in point_set:\n",
    "                point_set.remove(point)\n",
    "                filtered_fragment_list.append((point, image))\n",
    "        return filtered_fragment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_fragments(fragment_list, plot_size=(16, 16), one_dim_subplot_count=8):\n",
    "    plot_counter = 0\n",
    "    subplot_count = one_dim_subplot_count ** 2\n",
    "    for fragment in fragment_list:\n",
    "        if plot_counter % subplot_count == 0:\n",
    "            plt.figure(figsize=plot_size)\n",
    "        plot_counter += 1\n",
    "        plot_num = plot_counter % subplot_count\n",
    "        if plot_num == 0:\n",
    "            plot_num = subplot_count\n",
    "        plt.subplot(one_dim_subplot_count, one_dim_subplot_count, plot_num) \n",
    "        plt.imshow(fragment[1], cmap='gray', vmin=0, vmax=255)\n",
    "        if plot_counter % subplot_count == 0:\n",
    "            plt.show()\n",
    "\n",
    "def get_min_fragment_size(image):\n",
    "    return int(max(image.shape[0], image.shape[1]) / 100)\n",
    "\n",
    "def get_max_fragment_size(image):\n",
    "    return int(max(image.shape[0], image.shape[1]) / 10)\n",
    "            \n",
    "def resize_fragment(fragment):\n",
    "    return (fragment[0], cv2.resize(fragment[1], (32, 32))) \n",
    "\n",
    "def gray_fragment(fragment):\n",
    "    return (fragment[0], cv2.cvtColor(fragment[1], cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "def test_image(image, im_id):\n",
    "    det_params = DetectorParams(30, -30, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE, 3)\n",
    "    contours_detector = ContoursDetector(det_params)\n",
    "    contours_detector.plot_contours_images(image)\n",
    "    contour_list = contours_detector.get_contours(image)\n",
    "    fragment_extractor = ImageFragmentExtractor(image, 1.1)  \n",
    "    min_fragment_size = get_min_fragment_size(image)\n",
    "    max_fragment_size = get_max_fragment_size(image)    \n",
    "    image_fragment_filter = ImageFragmentFilter(min_fragment_size, max_fragment_size)    \n",
    "    fragment_list = map(fragment_extractor.extract_image_fragment, contour_list)\n",
    "    fragment_list = image_fragment_filter.filter_fragments(fragment_list)\n",
    "    fragment_list = map(lambda x: resize_fragment(x), fragment_list)\n",
    "    fragment_list = map(lambda x: gray_fragment(x), fragment_list)    \n",
    "    print(\"Fragments count: %d\" % (len(fragment_list)))\n",
    "    print(fragment_list[0][1])\n",
    "    pickle.dump(fragment_list, open(\"{0}.p\".format(im_id), \"wb\"))    \n",
    "    plot_fragments(fragment_list)\n",
    "    \n",
    "def test_params(filepath_list):\n",
    "    for filepath in filepath_list:\n",
    "        image = cv2.imread(filepath, 1)\n",
    "        test_image(image, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath_list = map(lambda x: \"keyboards/keyboard{0}.jpg\".format(x), [0, 4, 5, 7, 9])\n",
    "test_params(filepath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
